{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLxCg5n1_pIx"
      },
      "outputs": [],
      "source": [
        "! pip install -q transformers accelerate sentencepiece langchain chroma unstructured chromadb\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.chains import VectorDBQA\n",
        "from langchain.document_loaders import DirectoryLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcxVQ1Le_rJ3"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aemBjg48AQas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84a577c-5f91-4157-defc-a27602fa96a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "directory = \"/content/Docs\"  # Update the directory path accordingly\n",
        "\n",
        "def load_docs(directory):\n",
        "  loader = DirectoryLoader(directory)\n",
        "  documents = loader.load()\n",
        "  return documents\n",
        "\n",
        "documents = load_docs(directory)\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxphNKo1A72A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184a60e5-618c-4c24-8574-e9971e5f4903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a different task than the one specified in the repository. Be sure to know what you're doing :)\n",
            "WARNING:huggingface_hub.inference_api:You're using a different task than the one specified in the repository. Be sure to know what you're doing :)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "embeddings = HuggingFaceHubEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  return docs\n",
        "\n",
        "docs = split_docs(documents)\n",
        "print(len(docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMSskrWRX3mq",
        "outputId": "282f498d-f032-4cf2-b74a-42d9d35d0334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "tabCQCF3X8gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How to track my package\"\n",
        "num = 3\n",
        "matching_docs = db.similarity_search(query,num)\n",
        "print(matching_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBPISLzQX-iC",
        "outputId": "830226d4-9315-44e5-c72f-7683ea38ecf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content=\"You can find tracking information in your order details. If an order includes multiple items, each may have separate delivery dates and tracking information.\\n\\nGo to Your Orders. Go to the order you want to track. Select Track Package next to your order. Select See all updates to view delivery updates. Depending on the shipping method you chose, it's possible that the tracking information might not be visible immediately.\\n\\nItems sent by third-party sellers from the Amazon Marketplace can in some cases also be tracked. It's possible if the seller has shared this information with Amazon and you have chosen a traceable shipping method.\", metadata={'source': '/content/Docs/Track Your Package.txt'}), Document(page_content=\"Note: Some packages, such as standard international deliveries, aren't trackable. Other reasons why tracking information might not be available are listed on Missing Tracking Information. If the estimated delivery date for your package has passed and your tracking information hasn't changed, allow an additional day or two for the package to be delivered. Read more about our recommended actions on Late Deliveries.\\n\\nIf your package shows as delivered but you haven't yet received it, go to Find a Missing Package that Shows as Delivered to find out which steps you can take.\", metadata={'source': '/content/Docs/Track Your Package.txt'}), Document(page_content=\"If an item is missing from your package, it may have been shipped separately.\\n\\nIf you received your package and an item is missing, do the following:\\n\\nGo to Your Orders to see if your missing item is in another shipment. Next to the image of your item, select Track Package to find the delivery date for this shipment. If you still can't locate your item, contact us. Note: If your item is missing a part, contact the product's manufacturer for assistance. Manufacturer contact information can usually be found on the product packaging or in the paperwork included with the product. If you can't find contact information, or if they can't help, you can return the item. To do so, go to Your Orders and select Return or Replace Items. Tracking information shows that the shipment was delivered, but you can't find it? Go to Find a Missing Package That Shows As Delivered for more information.\", metadata={'source': '/content/Docs/Find a Missing Item from Your Package.txt'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"\n",
        "  \"Summarize:\n",
        "\"\"\"\n",
        "for document in matching_docs:\n",
        "      input_text += document.page_content\n",
        "print(input_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqXHt9pNYAPG",
        "outputId": "f0d885d9-c982-4835-8af5-65a84b5e1160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  \"Summarize:\n",
            "You can find tracking information in your order details. If an order includes multiple items, each may have separate delivery dates and tracking information.\n",
            "\n",
            "Go to Your Orders. Go to the order you want to track. Select Track Package next to your order. Select See all updates to view delivery updates. Depending on the shipping method you chose, it's possible that the tracking information might not be visible immediately.\n",
            "\n",
            "Items sent by third-party sellers from the Amazon Marketplace can in some cases also be tracked. It's possible if the seller has shared this information with Amazon and you have chosen a traceable shipping method.Note: Some packages, such as standard international deliveries, aren't trackable. Other reasons why tracking information might not be available are listed on Missing Tracking Information. If the estimated delivery date for your package has passed and your tracking information hasn't changed, allow an additional day or two for the package to be delivered. Read more about our recommended actions on Late Deliveries.\n",
            "\n",
            "If your package shows as delivered but you haven't yet received it, go to Find a Missing Package that Shows as Delivered to find out which steps you can take.If an item is missing from your package, it may have been shipped separately.\n",
            "\n",
            "If you received your package and an item is missing, do the following:\n",
            "\n",
            "Go to Your Orders to see if your missing item is in another shipment. Next to the image of your item, select Track Package to find the delivery date for this shipment. If you still can't locate your item, contact us. Note: If your item is missing a part, contact the product's manufacturer for assistance. Manufacturer contact information can usually be found on the product packaging or in the paperwork included with the product. If you can't find contact information, or if they can't help, you can return the item. To do so, go to Your Orders and select Return or Replace Items. Tracking information shows that the shipment was delivered, but you can't find it? Go to Find a Missing Package That Shows As Delivered for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summary using Langchain\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDc1qLZi1_-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summary(input_text):\n",
        "    max_length = 1024 # Adjust the max_length value as needed\n",
        "    tokens = tokenizer.encode(input_text, truncation=True, max_length=max_length, padding='max_length', return_tensors='pt')\n",
        "    tokens = tokens\n",
        "    outputs = model.generate(tokens)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(answer)\n",
        "\n",
        "summary(input_text)"
      ],
      "metadata": {
        "id": "PmOWHgIjYEu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f3278a-0d46-4847-8ec1-6449c0c12db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to Your Orders. Check your tracking information. Allow for late delivery. Find missing items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generation using Langchain"
      ],
      "metadata": {
        "id": "satXb5ND3gNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Enter your query : \")\n",
        "\n",
        "def generate(query):\n",
        "    num = 3\n",
        "    matching_docs = db.similarity_search(query,num)\n",
        "    temp = \"\"\n",
        "    for document in matching_docs:\n",
        "          temp += document.page_content\n",
        "    template = \"\"\"You are a helpful assistant that that can answer questions based on : \"\"\"\n",
        "    template += temp\n",
        "    template += \"\"\" Only use the factual information from the transcript to answer the question.Your answers should be verbose and detailed.\"\"\"\n",
        "    template += \"\"\"Question : \"\"\"\n",
        "    template += query\n",
        "    tokens = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    tokens = tokens\n",
        "    outputs = model.generate(tokens)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(answer)\n",
        "generate(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVQOfbCM4BFz",
        "outputId": "4afb552d-6281-4da2-b0e9-63343f621f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your queryfind my package\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to Your Orders. Check your tracking information. Allow for late delivery. Find missing items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prompt using LLM Chain\n"
      ],
      "metadata": {
        "id": "QR25ClhE2EGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
        "from langchain.prompts.chat import ( ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate)"
      ],
      "metadata": {
        "id": "UijPITBmC-e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response_from_query(db, query, k=4):\n",
        "    \"\"\"\n",
        "    Setting the chunksize to 1000 and k to 4 maximizes\n",
        "    the number of tokens to analyze.\n",
        "    \"\"\"\n",
        "\n",
        "    docs = db.similarity_search(query, k=k)\n",
        "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
        "\n",
        "    chat = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":1e-10})\n",
        "\n",
        "    # Template to use for the system message prompt\n",
        "    template = \"\"\"\n",
        "        You are a helpful assistant that that can answer questions\n",
        "        based on :  {docs}\n",
        "        Only use the factual information from the transcript to answer the question.\n",
        "        Your answers should be verbose and detailed.\n",
        "        \"\"\"\n",
        "    print(template)\n",
        "\n",
        "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "    # Human question prompt\n",
        "    human_template = \"Answer the following question: {question}\"\n",
        "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
        "\n",
        "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
        "\n",
        "    response = chain.run(question=query, docs=docs_page_content)\n",
        "    response = response.replace(\"\\n\", \"\")\n",
        "    return response, docs"
      ],
      "metadata": {
        "id": "Oa_o9W9JITE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "query = input(\"Enter your query : \")\n",
        "response, docs = get_response_from_query(db, query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dJ5ZfKtIbVV",
        "outputId": "da194df6-e96a-4a6e-f482-a8ff6b1c68c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query : find my package\n",
            "\n",
            "        You are a helpful assistant that that can answer questions \n",
            "        based on :  {docs}\n",
            "        Only use the factual information from the transcript to answer the question. \n",
            "        Your answers should be verbose and detailed.\n",
            "        \n",
            "If you received your package and an item is missing, do the following: Go to Your Order\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNQU1w_lLhfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
